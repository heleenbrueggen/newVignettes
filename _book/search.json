[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "newVignettesBook",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "CombiningInferences.html",
    "href": "CombiningInferences.html",
    "title": "6  mice: Combining inferences",
    "section": "",
    "text": "7 Correlations\n3. Calculate a correlation between all continuous variables for the imputed boys data\nThere are two ways in which we can calculate the correlation on the imputed data:\nQuite often people are suggesting that using the average imputed dataset - so taking the average over the imputed data set such that any realized cell depicts the average over the corresponding data in the imputed data - would be efficient and conform Rubin’s rules. This is not true. Doing this will yield false inference.\nTo demonstrate this, let’s create the averaged data set and exclude the non-numerical columns:\nave &lt;- imp %&gt;%\n  mice::complete(\"long\") %&gt;%\n  group_by(.id) %&gt;%\n  summarise_all(.funs = mean) %&gt;%\n  select(-.id, -.imp, -phb, -gen, -reg)\n\nhead(ave)\n\n# A tibble: 6 × 6\n    age   hgt   wgt   bmi    hc    tv\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.035  50.1  3.65  14.5  33.7   2.5\n2 0.038  53.5  3.37  11.8  35     3.5\n3 0.057  50    3.14  12.6  35.2   2.8\n4 0.06   54.5  4.27  14.4  36.7   2.5\n5 0.062  57.5  5.03  15.2  37.3   2  \n6 0.068  55.5  4.66  15.1  37     2.1\nIf we now calculate Pearson’s correlation, rounded to two digits:\ncor.wrong &lt;- ave %&gt;%\n  cor() %&gt;%\n  round(digits = 2)\nwe obtain:\ncor.wrong\n\n     age  hgt  wgt  bmi   hc   tv\nage 1.00 0.98 0.95 0.63 0.86 0.86\nhgt 0.98 1.00 0.94 0.60 0.91 0.81\nwgt 0.95 0.94 1.00 0.79 0.84 0.87\nbmi 0.63 0.60 0.79 1.00 0.60 0.64\nhc  0.86 0.91 0.84 0.60 1.00 0.67\ntv  0.86 0.81 0.87 0.64 0.67 1.00\nIt is best to do a Fisher transformation before pooling the correlation estimates - and a backtransformation afterwards. Therefore we define the following two functions that allow us to transform and backtransform any value:\nfisher.trans &lt;- function(x) 1/2 * log((1 + x) / (1 - x))\nfisher.backtrans &lt;- function(x) (exp(2 * x) - 1) / (exp(2 * x) + 1)\nNow, to calculate the correlation on the imputed data\ncor &lt;- imp %&gt;%\n  mice::complete(\"all\") %&gt;%\n  map(select, -phb, -gen, -reg) %&gt;%  \n  map(stats::cor) %&gt;%\n  map(fisher.trans)\ncor\n\n$`1`\n          age       hgt      wgt       bmi        hc        tv\nage       Inf 2.1971683 1.837486 0.7306936 1.2875134 1.1764013\nhgt 2.1971683       Inf 1.771810 0.6796283 1.5304395 1.0150829\nwgt 1.8374860 1.7718099      Inf 1.0661101 1.2173486 1.1632394\nbmi 0.7306936 0.6796283 1.066110       Inf 0.6755864 0.6965303\nhc  1.2875134 1.5304395 1.217349 0.6755864       Inf 0.7662706\ntv  1.1764013 1.0150829 1.163239 0.6965303 0.7662706       Inf\n\n$`2`\n          age       hgt      wgt       bmi        hc        tv\nage       Inf 2.1928290 1.839154 0.7396715 1.2805717 1.1540150\nhgt 2.1928290       Inf 1.772569 0.6866849 1.5335605 1.0247420\nwgt 1.8391536 1.7725691      Inf 1.0777861 1.2168596 1.1924681\nbmi 0.7396715 0.6866849 1.077786       Inf 0.6757144 0.7175002\nhc  1.2805717 1.5335605 1.216860 0.6757144       Inf 0.7716682\ntv  1.1540150 1.0247420 1.192468 0.7175002 0.7716682       Inf\n\n$`3`\n         age       hgt      wgt       bmi        hc        tv\nage      Inf 2.1980513 1.839317 0.7384530 1.2750962 1.1623767\nhgt 2.198051       Inf 1.772417 0.6877455 1.5248987 1.0039437\nwgt 1.839317 1.7724172      Inf 1.0774889 1.2124082 1.1611924\nbmi 0.738453 0.6877455 1.077489       Inf 0.6812475 0.7128481\nhc  1.275096 1.5248987 1.212408 0.6812475       Inf 0.7624198\ntv  1.162377 1.0039437 1.161192 0.7128481 0.7624198       Inf\n\n$`4`\n          age       hgt      wgt       bmi        hc        tv\nage       Inf 2.1961017 1.838918 0.7408736 1.2897920 1.1832366\nhgt 2.1961017       Inf 1.774843 0.6907368 1.5444453 1.0383982\nwgt 1.8389176 1.7748429      Inf 1.0800728 1.2256015 1.2125146\nbmi 0.7408736 0.6907368 1.080073       Inf 0.6827374 0.7359459\nhc  1.2897920 1.5444453 1.225601 0.6827374       Inf 0.7837830\ntv  1.1832366 1.0383982 1.212515 0.7359459 0.7837830       Inf\n\n$`5`\n          age      hgt      wgt       bmi        hc        tv\nage       Inf 2.195998 1.839240 0.7359324 1.2753551 1.1843788\nhgt 2.1959978      Inf 1.772784 0.6840920 1.5270459 1.0261064\nwgt 1.8392403 1.772784      Inf 1.0709307 1.2095539 1.1910395\nbmi 0.7359324 0.684092 1.070931       Inf 0.6742064 0.7114433\nhc  1.2753551 1.527046 1.209554 0.6742064       Inf 0.7587066\ntv  1.1843788 1.026106 1.191039 0.7114433 0.7587066       Inf\n\n$`6`\n          age       hgt      wgt       bmi        hc        tv\nage       Inf 2.1960817 1.839802 0.7380297 1.2683845 1.1098175\nhgt 2.1960817       Inf 1.773711 0.6872310 1.5185628 0.9710611\nwgt 1.8398023 1.7737114      Inf 1.0753483 1.2056839 1.1312176\nbmi 0.7380297 0.6872310 1.075348       Inf 0.6778270 0.6868663\nhc  1.2683845 1.5185628 1.205684 0.6778270       Inf 0.7000833\ntv  1.1098175 0.9710611 1.131218 0.6868663 0.7000833       Inf\n\n$`7`\n          age       hgt      wgt       bmi        hc        tv\nage       Inf 2.1962046 1.835994 0.7315759 1.2772518 1.1987818\nhgt 2.1962046       Inf 1.772959 0.6825245 1.5256606 1.0441973\nwgt 1.8359941 1.7729588      Inf 1.0685706 1.2150211 1.2020363\nbmi 0.7315759 0.6825245 1.068571       Inf 0.6805006 0.7139035\nhc  1.2772518 1.5256606 1.215021 0.6805006       Inf 0.7789061\ntv  1.1987818 1.0441973 1.202036 0.7139035 0.7789061       Inf\n\n$`8`\n          age       hgt      wgt       bmi        hc        tv\nage       Inf 2.1929580 1.840578 0.7439899 1.2888151 1.2043697\nhgt 2.1929580       Inf 1.773407 0.6923113 1.5404146 1.0468795\nwgt 1.8405779 1.7734068      Inf 1.0811815 1.2216658 1.2005007\nbmi 0.7439899 0.6923113 1.081182       Inf 0.6844591 0.7123828\nhc  1.2888151 1.5404146 1.221666 0.6844591       Inf 0.7906234\ntv  1.2043697 1.0468795 1.200501 0.7123828 0.7906234       Inf\n\n$`9`\n          age       hgt      wgt       bmi        hc        tv\nage       Inf 2.1955320 1.838406 0.7384463 1.2842531 1.1620413\nhgt 2.1955320       Inf 1.773995 0.6878719 1.5270096 1.0147341\nwgt 1.8384062 1.7739947      Inf 1.0758542 1.2183190 1.1719916\nbmi 0.7384463 0.6878719 1.075854       Inf 0.6857832 0.7065790\nhc  1.2842531 1.5270096 1.218319 0.6857832       Inf 0.7578655\ntv  1.1620413 1.0147341 1.171992 0.7065790 0.7578655       Inf\n\n$`10`\n          age      hgt      wgt       bmi        hc        tv\nage       Inf 2.194992 1.840380 0.7412752 1.2769159 1.1855404\nhgt 2.1949924      Inf 1.773964 0.6897810 1.5248482 1.0468461\nwgt 1.8403795 1.773964      Inf 1.0783437 1.2142874 1.2146691\nbmi 0.7412752 0.689781 1.078344       Inf 0.6849574 0.7124170\nhc  1.2769159 1.524848 1.214287 0.6849574       Inf 0.7733416\ntv  1.1855404 1.046846 1.214669 0.7124170 0.7733416       Inf\nThe object cor is a list over the \\(m\\) imputations where each listed index is a correlation matrix. To calculate the average over the correlation matrices, we can add the \\(m\\) listed indices and divide them by \\(m\\):\ncor.rect &lt;- Reduce(\"+\", cor) / length(cor) # m is equal to the length of the list\ncor.rect &lt;- fisher.backtrans(cor.rect)\nIf we compare the wrong estimates in cor.wrong\ncor.wrong\n\n     age  hgt  wgt  bmi   hc   tv\nage 1.00 0.98 0.95 0.63 0.86 0.86\nhgt 0.98 1.00 0.94 0.60 0.91 0.81\nwgt 0.95 0.94 1.00 0.79 0.84 0.87\nbmi 0.63 0.60 0.79 1.00 0.60 0.64\nhc  0.86 0.91 0.84 0.60 1.00 0.67\ntv  0.86 0.81 0.87 0.64 0.67 1.00\nwith the correct estimates in cor.rect\nround(cor.rect, digits = 2)\n\n     age  hgt  wgt  bmi   hc   tv\nage  NaN 0.98 0.95 0.63 0.86 0.82\nhgt 0.98  NaN 0.94 0.60 0.91 0.77\nwgt 0.95 0.94  NaN 0.79 0.84 0.83\nbmi 0.63 0.60 0.79  NaN 0.59 0.61\nhc  0.86 0.91 0.84 0.59  NaN 0.64\ntv  0.82 0.77 0.83 0.61 0.64  NaN\nWe see that the wrong estimates in cor.wrong have the tendency to overestimate the correlation coefficient that is correctly combined following Rubin’s rules.\nThe correct estimates have a diagonal of NaN’s, because the tranformation of a correlation of 1 yields Inf and the backtransformation of Inf has no representation in real number space. We know the diagonal is supposed to be 1, so we can simply correct this\ndiag(cor.rect) &lt;- 1\ncor.rect\n\n          age       hgt       wgt       bmi        hc        tv\nage 1.0000000 0.9755309 0.9506921 0.6278711 0.8565901 0.8249429\nhgt 0.9755309 1.0000000 0.9439641 0.5959615 0.9103713 0.7711664\nwgt 0.9506921 0.9439641 1.0000000 0.7914006 0.8383737 0.8287360\nbmi 0.6278711 0.5959615 0.7914006 1.0000000 0.5917157 0.6110790\nhc  0.8565901 0.9103713 0.8383737 0.5917157 1.0000000 0.6436419\ntv  0.8249429 0.7711664 0.8287360 0.6110790 0.6436419 1.0000000",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>`mice`: Combining inferences</span>"
    ]
  },
  {
    "objectID": "CombiningInferences.html#why-does-the-average-data-set-not-serve-as-a-good-basis-for-analysis",
    "href": "CombiningInferences.html#why-does-the-average-data-set-not-serve-as-a-good-basis-for-analysis",
    "title": "6  mice: Combining inferences",
    "section": "7.1 Why does the average data set not serve as a good basis for analysis?",
    "text": "7.1 Why does the average data set not serve as a good basis for analysis?\nIn FIMD v2, paragraph 5.1.2 Stef mentions the following:\n\nThe average workflow is faster and easier than the correct methods, since there is no need to replicate the analyses \\(m\\) times. In the words of Dempster and Rubin (1983), this workflow is\nseductive because it can lull the user into the pleasurable state of believing that the data are complete after all.\nThe ensuing statistical analysis does not know which data are observed and which are missing, and treats all data values as real, which will underestimate the uncertainty of the parameters. The reported standard errors and p-values after data-averaging are generally too low. The correlations between the variables of the averaged data will be too high. For example, the correlation matrix in the average data are more extreme than the average of the \\(m\\) correlation matrices, which is an example of ecological fallacy. As researchers tend to like low p-values and high correlations, there is a cynical reward for the analysis of the average data. However, analysis of the average data cannot give a fair representation of the uncertainties associated with the underlying data, and hence is not recommended.\n\n\nSo, please stay away from averaging the imputed data sets. Instead, use the correct workflow of analyzing the imputed sets separately and combining the inference afterwards.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>`mice`: Combining inferences</span>"
    ]
  }
]